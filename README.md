# LLM-research

# Fine tuning LLMs 

In this repo we have done two types of fine tuning:

1. With QLora (Quantized Low rank adaptation)
2. With PEFT (Parameter Efficient Fine Tuning)

Here are codes available for finetuning 3 models

1. Falcon
2. Llama-2
3. mpt 

# Inference

Inference code is also available in this repo. 

This repo is basically a research repo, it's not organized. I have played around with different methods and processes to figure out which finetuning method works well for LLMs. A more organized codebase will be found in my [Medical-LLM](https://github.com/asif-mahmud-am/Medical-LLM) repo. 